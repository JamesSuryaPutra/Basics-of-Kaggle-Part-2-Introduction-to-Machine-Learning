<Recap>
You've built a model. In this exercise you will test how good your model is.
Run the cell below to set up your coding environment where the previous exercise left off.

****************
# Code you have previously used to load data
import pandas as pd
from sklearn.tree import DecisionTreeRegressor

# Path of the file to read
iowa_file_path = '../input/home-data-for-ml-course/train.csv'

home_data = pd.read_csv(iowa_file_path)
y = home_data.SalePrice
feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']
X = home_data[feature_columns]

# Specify Model
iowa_model = DecisionTreeRegressor()
# Fit Model
iowa_model.fit(X, y)

print("First in-sample predictions:", iowa_model.predict(X.head()))
print("Actual target values for those homes:", y.head().tolist())

# Set up code checking
from learntools.core import binder
binder.bind(globals())
from learntools.machine_learning.ex4 import *
print("Setup Complete")

First in-sample predictions: [208500. 181500. 223500. 140000. 250000.]
Actual target values for those homes: [208500, 181500, 223500, 140000, 250000]
Setup Complete
****************

<1st step: Split your data>
Use the train_test_split function to split up your data.
Give it the argument random_state=1 so the check functions know what to expect when verifying your code.
Recall, your features are loaded in the DataFrame X and your target is loaded in y.

****************
# Import the train_test_split function and uncomment
from sklearn.model_selection import train_test_split

# fill in and uncomment
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)

# Check your answer
step_1.check()

Correct

# The lines below will show you a hint or the solution.
step_1.hint() 
step_1.solution()

Hint:
The function you need to import is part of sklearn. When calling the function, the arguments are X and y. Ensure you set the random_state to 1.

Solution:
from sklearn.model_selection import train_test_split
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)
****************

<2nd step: Specify and fit the model>
Create a DecisionTreeRegressor model and fit it to the relevant data. Set random_state to 1 again when creating the model.

****************
# You imported DecisionTreeRegressor in your last exercise
# and that code has been copied to the setup code above. So, no need to
# import it again

# Specify the model
iowa_model = DecisionTreeRegressor(random_state=1)

# Fit iowa_model with the training data.
iowa_model.fit(train_X, train_y)

# Check your answer
step_2.check()

[186500. 184000. 130000.  92000. 164500. 220000. 335000. 144152. 215000.
 262000.]
[186500. 184000. 130000.  92000. 164500. 220000. 335000. 144152. 215000.
 262000.]
Correct

step_2.hint()
step_2.solution()

Hint:
Remember, you fit with training data. You will test with validation data soon.

Solution:
iowa_model = DecisionTreeRegressor(random_state=1)
iowa_model.fit(train_X, train_y)
****************

<3rd step: Make Predictions with Validation Data>

****************
# Predict with all validation observations
val_predictions = iowa_model.predict(val_X)

# Check your answer
step_3.check()

Correct

step_3.hint()
step_3.solution()

Hint:
Run predict on the right validation data object.

Solution:
val_predictions = iowa_model.predict(val_X)

Inspect your predictions and actual values from validation data.

# print the top few validation predictions
print(val_X)
# print the top few actual prices from validation data
print(val_y)

LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \
258     12435       2001       963       829         2             3   
267      8400       1939      1052       720         2             4   
288      9819       1967       900         0         1             3   
649      1936       1970       630         0         1             1   
1233    12160       1959      1188         0         1             3   
...       ...        ...       ...       ...       ...           ...   
1017     5814       1984      1360         0         1             1   
534      9056       2004       707       707         2             3   
1334     2368       1970       765       600         1             3   
1369    10635       2003      1668         0         2             3   
628     11606       1969      1040      1040         1             5   

      TotRmsAbvGrd  
258              7  
267              8  
288              5  
649              3  
1233             6  
...            ...  
1017             4  
534              6  
1334             7  
1369             8  
628              9  

[365 rows x 7 columns]
258     231500
267     179500
288     122000
649      84500
1233    142000
         ...  
1017    187500
534     178000
1334    125000
1369    232000
628     135000
Name: SalePrice, Length: 365, dtype: int64

What do you notice that is different from what you saw with in-sample predictions (which are printed after the top code cell in this page).
Do you remember why validation predictions differ from in-sample (or training) predictions? This is an important idea from the last lesson.
****************

<4th step: Calculate the Mean Absolute Error (MAE) in Validation Data>

****************
from sklearn.metrics import mean_absolute_error
val_mae = mean_absolute_error(val_y, val_predictions)

# uncomment following line to see the validation_mae
print(val_mae)

# Check your answer
step_4.check()

29652.931506849316
Correct

step_4.hint()
step_4.solution()

Hint:
The order of arguments to mean_absolute_error doesn't matter. Make sure you fit to only the training data in step 2.

Solution:
val_mae = mean_absolute_error(val_y, val_predictions)

Is that MAE good? There isn't a general rule for what values are good that applies across applications. But you'll see how to use (and improve) this number in the next step.
****************
